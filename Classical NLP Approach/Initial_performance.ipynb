{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sparse.load_npz(\"Data/xtest.npy.npz\")\n",
    "y_test = np.load(\"Data/ytest.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = joblib.load(\"Models/Initial/Logistic Regression.pk1\")\n",
    "tree = joblib.load(\"Models/Initial/Decision Tree.pk1\")\n",
    "knn = joblib.load(\"Models/Initial/KNN.pk1\")\n",
    "mnb = joblib.load(\"Models/Initial/Multinomial Naive Bayes.pk1\")\n",
    "gnb = joblib.load(\"Models/Initial/Gaussian Naive Bayes.pk1\")\n",
    "svc = joblib.load(\"Models/Initial/SVC.pk1\")\n",
    "gboost = joblib.load(\"Models/Initial/Gradient Boosting.pk1\")\n",
    "ada = joblib.load(\"Models/Initial/AdaBoost.pk1\")\n",
    "forest = joblib.load(\"Models/Initial/Random Forest.pk1\")\n",
    "cat = joblib.load(\"Models/Initial/CatBoost.pk1\")\n",
    "light = joblib.load(\"Models/Initial/LightGBM.pk1\")\n",
    "xgb = joblib.load(\"Models/Initial/XGBoost.pk1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  'Logistic Regression': lreg,\n",
    "  'Decision Tree': tree,\n",
    "  'KNN': knn,\n",
    "  'Multinomial Naive Bayes': mnb,\n",
    "  'Gaussian Naive Bayes': gnb,      \n",
    "  'SVC': svc,\n",
    "  'AdaBoost': ada,\n",
    "  'Gradient Boosting': gboost,\n",
    "  'Random Forest': forest,\n",
    "  'XGBoost': xgb,\n",
    "  'CatBoost': cat,\n",
    "  'LightGBM': light\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Precision_2</th>\n",
       "      <th>Precision_3</th>\n",
       "      <th>Precision_4</th>\n",
       "      <th>Precision_5</th>\n",
       "      <th>Precision_6</th>\n",
       "      <th>Precision_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>f1-score_3</th>\n",
       "      <th>f1-score_4</th>\n",
       "      <th>f1-score_5</th>\n",
       "      <th>f1-score_6</th>\n",
       "      <th>f1-score_7</th>\n",
       "      <th>f1-score_8</th>\n",
       "      <th>f1-score_9</th>\n",
       "      <th>f1-score_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  Accuracy  Precision_0  Precision_1  Precision_2  \\\n",
       "0       Logistic Regression     0.649        0.570        0.761        0.474   \n",
       "1             Decision Tree     0.356        0.316        0.220        0.218   \n",
       "2                       KNN     0.494        0.437        0.500        0.279   \n",
       "3   Multinomial Naive Bayes     0.383        0.473        1.000        0.000   \n",
       "4      Gaussian Naive Bayes     0.389        0.395        0.532        0.229   \n",
       "5                       SVC     0.633        0.500        0.788        0.554   \n",
       "6                  AdaBoost     0.425        0.272        0.500        0.283   \n",
       "7         Gradient Boosting     0.573        0.489        0.630        0.380   \n",
       "8             Random Forest     0.540        0.488        0.696        0.343   \n",
       "9                   XGBoost     0.140        0.000        1.000        0.000   \n",
       "10                 CatBoost     0.620        0.561        0.636        0.399   \n",
       "11                 LightGBM     0.617        0.543        0.644        0.393   \n",
       "\n",
       "    Precision_3  Precision_4  Precision_5  Precision_6  Precision_7  ...  \\\n",
       "0         0.529        0.680        0.867        0.571        0.664  ...   \n",
       "1         0.125        0.434        0.470        0.049        0.464  ...   \n",
       "2         0.246        0.526        0.578        0.389        0.530  ...   \n",
       "3         0.000        0.236        0.000        0.000        0.808  ...   \n",
       "4         0.190        0.325        0.467        0.048        0.496  ...   \n",
       "5         0.500        0.709        0.889        0.500        0.686  ...   \n",
       "6         0.250        0.464        0.646        0.231        0.367  ...   \n",
       "7         0.389        0.656        0.680        0.393        0.646  ...   \n",
       "8         0.750        0.501        0.773        0.500        0.508  ...   \n",
       "9         0.000        0.487        0.071        0.095        1.000  ...   \n",
       "10        0.552        0.688        0.738        0.552        0.631  ...   \n",
       "11        0.500        0.683        0.740        0.538        0.672  ...   \n",
       "\n",
       "    f1-score_1  f1-score_2  f1-score_3  f1-score_4  f1-score_5  f1-score_6  \\\n",
       "0        0.694       0.431       0.209       0.759       0.680       0.116   \n",
       "1        0.237       0.214       0.128       0.436       0.443       0.049   \n",
       "2        0.516       0.314       0.239       0.610       0.471       0.286   \n",
       "3        0.019       0.000       0.000       0.382       0.000       0.000   \n",
       "4        0.457       0.107       0.089       0.432       0.304       0.024   \n",
       "5        0.681       0.402       0.104       0.758       0.653       0.061   \n",
       "6        0.211       0.252       0.094       0.492       0.532       0.136   \n",
       "7        0.548       0.369       0.267       0.691       0.607       0.244   \n",
       "8        0.424       0.329       0.082       0.618       0.496       0.061   \n",
       "9        0.019       0.000       0.000       0.244       0.061       0.048   \n",
       "10       0.618       0.444       0.327       0.737       0.608       0.352   \n",
       "11       0.595       0.398       0.303       0.727       0.651       0.318   \n",
       "\n",
       "    f1-score_7  f1-score_8  f1-score_9  f1-score_10  \n",
       "0        0.712       0.725       0.435        0.926  \n",
       "1        0.456       0.489       0.223        0.595  \n",
       "2        0.501       0.658       0.177        0.797  \n",
       "3        0.563       0.144       0.101        0.813  \n",
       "4        0.415       0.442       0.233        0.649  \n",
       "5        0.720       0.734       0.423        0.935  \n",
       "6        0.489       0.584       0.190        0.774  \n",
       "7        0.663       0.690       0.331        0.878  \n",
       "8        0.630       0.639       0.236        0.839  \n",
       "9        0.011       0.043       0.000        0.219  \n",
       "10       0.677       0.741       0.412        0.873  \n",
       "11       0.699       0.722       0.425        0.896  \n",
       "\n",
       "[12 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_performance = compare_performance(models, x_test.toarray(), y_test)\n",
    "initial_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name  Accuracy  Precision_0  Precision_1  Precision_2  \\\n",
      "0       Logistic Regression     0.649        0.570        0.761        0.474   \n",
      "1             Decision Tree     0.356        0.316        0.220        0.218   \n",
      "2                       KNN     0.494        0.437        0.500        0.279   \n",
      "3   Multinomial Naive Bayes     0.383        0.473        1.000        0.000   \n",
      "4      Gaussian Naive Bayes     0.389        0.395        0.532        0.229   \n",
      "5                       SVC     0.633        0.500        0.788        0.554   \n",
      "6                  AdaBoost     0.425        0.272        0.500        0.283   \n",
      "7         Gradient Boosting     0.573        0.489        0.630        0.380   \n",
      "8             Random Forest     0.540        0.488        0.696        0.343   \n",
      "9                   XGBoost     0.140        0.000        1.000        0.000   \n",
      "10                 CatBoost     0.620        0.561        0.636        0.399   \n",
      "11                 LightGBM     0.617        0.543        0.644        0.393   \n",
      "\n",
      "    Precision_3  Precision_4  Precision_5  Precision_6  Precision_7  ...  \\\n",
      "0         0.529        0.680        0.867        0.571        0.664  ...   \n",
      "1         0.125        0.434        0.470        0.049        0.464  ...   \n",
      "2         0.246        0.526        0.578        0.389        0.530  ...   \n",
      "3         0.000        0.236        0.000        0.000        0.808  ...   \n",
      "4         0.190        0.325        0.467        0.048        0.496  ...   \n",
      "5         0.500        0.709        0.889        0.500        0.686  ...   \n",
      "6         0.250        0.464        0.646        0.231        0.367  ...   \n",
      "7         0.389        0.656        0.680        0.393        0.646  ...   \n",
      "8         0.750        0.501        0.773        0.500        0.508  ...   \n",
      "9         0.000        0.487        0.071        0.095        1.000  ...   \n",
      "10        0.552        0.688        0.738        0.552        0.631  ...   \n",
      "11        0.500        0.683        0.740        0.538        0.672  ...   \n",
      "\n",
      "    f1-score_1  f1-score_2  f1-score_3  f1-score_4  f1-score_5  f1-score_6  \\\n",
      "0        0.694       0.431       0.209       0.759       0.680       0.116   \n",
      "1        0.237       0.214       0.128       0.436       0.443       0.049   \n",
      "2        0.516       0.314       0.239       0.610       0.471       0.286   \n",
      "3        0.019       0.000       0.000       0.382       0.000       0.000   \n",
      "4        0.457       0.107       0.089       0.432       0.304       0.024   \n",
      "5        0.681       0.402       0.104       0.758       0.653       0.061   \n",
      "6        0.211       0.252       0.094       0.492       0.532       0.136   \n",
      "7        0.548       0.369       0.267       0.691       0.607       0.244   \n",
      "8        0.424       0.329       0.082       0.618       0.496       0.061   \n",
      "9        0.019       0.000       0.000       0.244       0.061       0.048   \n",
      "10       0.618       0.444       0.327       0.737       0.608       0.352   \n",
      "11       0.595       0.398       0.303       0.727       0.651       0.318   \n",
      "\n",
      "    f1-score_7  f1-score_8  f1-score_9  f1-score_10  \n",
      "0        0.712       0.725       0.435        0.926  \n",
      "1        0.456       0.489       0.223        0.595  \n",
      "2        0.501       0.658       0.177        0.797  \n",
      "3        0.563       0.144       0.101        0.813  \n",
      "4        0.415       0.442       0.233        0.649  \n",
      "5        0.720       0.734       0.423        0.935  \n",
      "6        0.489       0.584       0.190        0.774  \n",
      "7        0.663       0.690       0.331        0.878  \n",
      "8        0.630       0.639       0.236        0.839  \n",
      "9        0.011       0.043       0.000        0.219  \n",
      "10       0.677       0.741       0.412        0.873  \n",
      "11       0.699       0.722       0.425        0.896  \n",
      "\n",
      "[12 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(initial_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_performance.to_csv(\"Models/Initial/Initial_perf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
